---
title: "ESM244 HW2"
author: "Sara Orofino"
date: "2/6/2019"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}

#load packages
library(tidyverse)
library(RColorBrewer)
library(tinytex)
library(boot)
library(beyonce)

# read in data 
fish <- read_csv("fish_catch_clean.csv")
cetacean <- read_csv("captive_cetacean_regions.csv")
```


#{.tabset}
##Task 1

###Data Visualization - Cetaceans in Captivity

```{r wrangle1, message=FALSE, warning=FALSE}

# Organize origin_location by US region according to US Census Bureau:
# West - Marineland of the Pacific, SeaWorld San Diego, Six Flags Discovery Kingdom, Dolphin Experience, Dolphin Quest Hawaii, Kahala Hilton Oahu, Sea Life Park, Mirage Dolphin Habitat
## West includes Hawaii, California, Nevada
# South - Discovery Cove, Dolphin Connection, Dolphin Research Center, Dolphin Plus Bayside, Dolphin Plus Oceanside, Gulf Wolrd Marine Park, Gulfarium, Marineland Florida, Miami Sequarium, Theater of the Sea, SeaWorld San Antonio, Georgia Aquarium,  
## South includes Florida, Texas, Georgia, 
# Midwest - Minnesota Zoo, Indianapolis Zoo, Brookfield Zoo, Shedd Aquarium, SeaWorld of Ohio, SeaWorld Aurora 
## Midwest includes Minnesota, Indiana, Ohio and Illinois 
# Northeast - National Aquarium, New England Aquarium 
## Northeast - Maryland and Massachusetts 
# Military - U.S. Navy and U.S. Navy MMP 
# International - Dolphin Quest Bermuda, Marineland Antibes, Marineland Canada, Sealand of the Pacific

acq_data <- cetacean %>% 
    filter(acquisition =="Born",
           birthYear != "NA",
           birthYear >= 1990,
           birthYear <= 2015) %>% 
  select(species, birthYear, us_regions) %>% 
  group_by(us_regions, birthYear) %>% 
  count() 

```


```{r}

#stacked column graph 

ggplot(acq_data, aes(x = birthYear, y = n , group = us_regions, fill = us_regions))+
  geom_bar(stat = "identity") + 
  scale_y_continuous(expand = c(0,0), limits = c(0,31), breaks = seq(0,30, by = 5)) + 
  scale_x_discrete(expand = c(0,0)) + 
  scale_fill_manual(values = beyonce_palette(74),
                    labels = c("International", "U.S. Midwest", "U.S. Military",
                                 "U.S. Northeast", "U.S. South", "U.S. West","Unknown")) +
  theme_classic()+
  guides(fill=guide_legend(title="Region of Origin")) +
  labs(y = "Number of Cetaceans",
       x  = "Year") + 
  coord_flip()

```

**Figure 1. Cetaceans Born in Captivity by Region 1990-2015.** The graph depicts the number of cetaceans born into captivity each year from 1990-2015. Data only includes cetaceans whose birth years are known. Each color indicates the proportion of cetaceans born in each region for the given year. Regions distinctions in the United States are based on census regions from the United States Census Bureau.  
Data: Amber Thomas, The Pudding  
Sources: U.S. National Marine Mammal Inventory June 2015, Ceta-Base May 2017. 



##Task 2 

###Parameter Estimation - Wild Fish Catch 

a. Exploratory Graph of wild catch over time:
  
```{r exploratory_graph, echo=FALSE}

colnames(fish) <- c("year", "wild", "farmed", "total") 

fish_growth <- fish %>% 
  mutate(time = 0:62) %>% 
  select(time, wild)
  
  
  
ggplot(fish_growth, aes(x=time, y=wild)) +
  geom_point() + 
  scale_y_continuous(limits = c(0,100), breaks = seq(0,100, by =20))


```

b. What type of relationship describes the trend?  

The graph depicts logistic growth.  

*Mathematically:*    

$N_t = \left(\frac{A}{1 + \beta e^{-rt}}\right)$  
  
    
*Initial Parameter estimates (A, $\beta$, and r):*  
  

Carrying Capacity (A) from the exploratory graph above:  
A = 90 million tons

If $N_0 = 17$ million tons estimate $\beta$:  
  
$\beta = \frac{(K - N_0)}{N_0}$   
  
$\beta = \frac{(90-17)}{17} = 4.294$  

```{r estimate_b, include=FALSE}

Bestimate <- (90-17)/17
```

Estimate r:

$r = 0.06648$   

```{r estimate_r, include=FALSE}

lag_phase <- fish_growth %>% 
  filter(time < 19, time > 14)
  
ggplot(lag_phase, aes(x= time, y = log(wild))) +
  geom_point()
  
lm(log(wild) ~ time, data = lag_phase)

#r=0.006648
```

c. Model Parameters using Nonlinear Least Squares:   

```{r}

fish_fit <- nls(wild ~ A/(1+B*exp(-r*time)),
                start = list(A = 90, B = 4.29, r = 0.06648),
                data = fish_growth)

# store coefficients for final graph:

A <- coef(fish_fit)[1]
B <- coef(fish_fit)[2]
r <- coef(fish_fit)[3]
```
Carrying Capacity (A):  
$A = 100.28$ million tons   

($\beta$):  
$\beta =  4.316$   

Growth Rate (r):  
$r = 0.06989$    

d. Finalized Graph:  
  
```{r final_graph, message=FALSE, warning=FALSE}

# Create a new sequence of time values to make predictions and model it: 

time_seq <- seq(0,70, length=100) 

fish_pred <- A/(1+B*exp(-r*time_seq))

# Bind with time sequence data:

pred_df <- data.frame(time_seq, fish_pred)

#Final graph: 

ggplot(fish_growth, aes(x = time, y = wild)) +
  geom_point(color = "slategray", size = 2, alpha = 0.7) +
  geom_line(data = pred_df, aes(x = time_seq, y = fish_pred), color = "midnightblue", size = 1) + 
  scale_x_continuous(expand = c(0,0.5), limits = c(0,70), breaks = seq(0,70, by = 10)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,100)) +
  labs(x = "Time \n(Time 0 = 1950)", y = "Wild Fish Catch (Million Tons)") +
  theme_bw() 

```

##Task 3 

###Boostrapped Confidence Interval for Proportions 

a. Bootstrapping

```{r bootstrap, warning=FALSE, message=FALSE}

# Goal: CI for proportion of nonbinary/genderqueer students experiencing exclusionary conduct

# n = 36; 0=did not experience exclusionary conduct, 1= did experience exclusionary conduct 
# Original data - 22 out of 36 did experience exclusionary conduct 

# Create a vector of proportions to use for bootstrapping: 

conduct <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0)

# Using the mean for the function will add up all the number but the number given will be the same as the number of 1s in the set; dividing by the total 36 will give the proportion of 1s

# test using the mean to get the proportion with the conduct vector:
mean(conduct)

#Mean is 0.6111 and the proportion is 61% - matches the given in the UCSB dataset

# Create a function using mean() to estimate the proportion of "1"s:

proportion_fun <- function(x,i) {mean(x[i])}

# Bootstrapping with 10,000:
boot_10000<-boot(conduct, proportion_fun, R=10000)

# Bootstrap with 100,000:
boot_100000<-boot(conduct, proportion_fun, R=100000)

#Bias decresaed but standard error isn't changing much


```

b. Histogram of Boostrapped Samples:

```{r histogram, message=FALSE, warning = FALSE}
k <- 2*((NROW(boot_100000$t))^(1/3))

ggplot() +
  aes(boot_100000$t) +
  geom_histogram(bins = k) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,15000)) +
  theme_bw()

```

c. Confidence Interval Statement:  

```{r boostrap_ci, include=FALSE}

boot.ci(boot_100000, conf = 0.95)

# Percentile CI (0.4444, 0.7778)
```


With repeated sampling (n=36), we would expect the proportion of UCSB students identifying as nonbinary or genderqueer who experience exclusionary, hostile, or intimidating conduct to fall between 44.4% and 77.8%.   

##Task 4

###R-Studio Conference Talks 


######Talk 1:  

Title - Visualizing uncertainty with hypothetical outcome plots   
Speaker - Claus Wilke   
* A hypothetical outcome plot is a way to represent variations in the data by representing various hypothetical outcomes all at once.   
* Created the ungeviz package which allows for inclusion of bootstrapped samples within geom_smooth, can be paired with gganimate to animate the uncertainty curve.   

Question: Is there a way to make boostrapped samples reproducible using boostrapper within ggplot?      

######Talk 2:
Title -  Spatial data science in the Tidyverse  
Speaker - Edzer Pebesma 
* Stars package extends spatial tables into raster and vector data cubes.   
* Raster data cubes have x and y spatial dimensions whereas vector data cubes have a set of feature geometries with at least one dimension.       
  
Question: Is there a way to animate changes in time dependent spatial data?    


######Talk 3:
Title - Cultivating creativity in data work   
Speaker - Hilary Parker  
* Much of data science in the past has focused on the process of tidying data and bringing into usable formats, but hasn't focused as much on the actual data collection. Stepping back to think about the process of data collection can facilitate new lines of investigation.       
* Stich Fix implemented a "Style Shuffle" visual rating tool to their app in order to gather more data points per individual allow for enhanced analysis of personal style choices.   

Question: What are some factors that we can consider when trying to develop research questions that are more amenable to design thinking?       
 